{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import dgl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]]],\n",
       "\n",
       "\n",
       "        [[[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]]],\n",
       "\n",
       "\n",
       "        [[[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]]],\n",
       "\n",
       "\n",
       "        [[[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]],\n",
       "\n",
       "         [[8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.],\n",
       "          [8., 8.]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 4\n",
    "N =6\n",
    "C = 2\n",
    "8 * torch.ones(d, N, N, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.]],\n",
       "\n",
       "         [[2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.]],\n",
       "\n",
       "         [[2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.]],\n",
       "\n",
       "         [[2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.]],\n",
       "\n",
       "         [[2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.]],\n",
       "\n",
       "         [[2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.],\n",
       "          [2.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*torch.ones(1,N,N,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]]],\n",
       "\n",
       "\n",
       "        [[[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]]],\n",
       "\n",
       "\n",
       "        [[[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]]],\n",
       "\n",
       "\n",
       "        [[[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]],\n",
       "\n",
       "         [[4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.],\n",
       "          [4., 4.]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(8 * torch.ones(d, N, N, C),  2 * torch.ones(1, N, N, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessData(data, data_name=\"mutagenicity\", processed_data_dir=\"processed_data\"):\n",
    "    # Unpack the data into graphs and labels\n",
    "    graphs, labels = zip(*data)\n",
    "    print(type(graphs))\n",
    "    # Preprocess each graph in the dataset\n",
    "    for graph in graphs:\n",
    "        # Compute the shortest distance matrix\n",
    "        shortest_dist_matrix = dgl.shortest_dist(graph)\n",
    "\n",
    "        # Calculate normalization distance matrix (binary matrix where 1 means the nodes are connected)\n",
    "        normalization_distance_matrix = 1 * (\n",
    "            shortest_dist_matrix[..., :, None] == shortest_dist_matrix[..., None, :]\n",
    "        ).sum(-1)\n",
    "\n",
    "        # Calculate distance matrix (inverse of shortest distance)\n",
    "        distance_matrix = 1 / (1 + shortest_dist_matrix)\n",
    "\n",
    "        # Add these matrices as node features\n",
    "        graph.ndata[\"normalization_distance_matrix\"] = normalization_distance_matrix\n",
    "        graph.ndata[\"distance_matrix\"] = distance_matrix.float()\n",
    "\n",
    "    # Ensure the directory exists for saving the processed data\n",
    "    os.makedirs(processed_data_dir, exist_ok=True)\n",
    "\n",
    "    # Define the path to save the entire dataset\n",
    "    processed_data_path = os.path.join(processed_data_dir, f\"{data_name}_processed\")\n",
    "\n",
    "    # Optionally save labels along with graphs (in a dictionary)\n",
    "    labels_dict = {\"labels\": torch.tensor(labels)}\n",
    "    \n",
    "    # Save the entire dataset (graphs + labels) using dgl.save_graphs\n",
    "    dgl.save_graphs(processed_data_path + \"_graphs.bin\", list(graphs), labels=labels_dict)\n",
    "\n",
    "    print(f\"Entire processed dataset saved to {processed_data_path}_graphs.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl\n",
    "import random\n",
    "import torch\n",
    "from dgl.data import LegacyTUDataset\n",
    "from preprocessdata import preProcessData\n",
    "\n",
    "\n",
    "def getData(processed_data_dir=\"processed_data/mutagenicity_processed_graphs.bin\"):\n",
    "    if os.path.exists(processed_data_dir):\n",
    "        graphs, label_dict = dgl.load_graphs(processed_data_dir)\n",
    "    else:\n",
    "        data = LegacyTUDataset(\"Mutagenicity\")\n",
    "        preProcessData(data)  # Your preprocessing function\n",
    "        graphs, label_dict = dgl.load_graphs(processed_data_dir)\n",
    "\n",
    "    # Get labels from the label_dict (assuming each graph corresponds to a label)\n",
    "    labels = label_dict[\"labels\"]\n",
    "\n",
    "    # Randomly select 500 graphs from the dataset\n",
    "    selected_indices = random.sample(range(len(graphs)), 500)\n",
    "    selected_graphs = [graphs[i] for i in selected_indices]\n",
    "    selected_labels = [labels[i] for i in selected_indices]\n",
    "\n",
    "    # Split the selected 500 graphs into 300 for training, 100 for validation, and 100 for testing\n",
    "    train_graphs, valid_graphs, test_graphs = (\n",
    "        selected_graphs[:300],\n",
    "        selected_graphs[300:400],\n",
    "        selected_graphs[400:],\n",
    "    )\n",
    "    train_labels, valid_labels, test_labels = (\n",
    "        selected_labels[:300],\n",
    "        selected_labels[300:400],\n",
    "        selected_labels[400:],\n",
    "    )\n",
    "\n",
    "    # Prepare the train, valid, and test data as pairs of graph and label\n",
    "    train_data = list(zip(train_graphs, train_labels))\n",
    "    valid_data = list(zip(valid_graphs, valid_labels))\n",
    "    test_data = list(zip(test_graphs, test_labels))\n",
    "\n",
    "    # Determine the number of features and classes\n",
    "    num_feats = (\n",
    "        selected_graphs[0].ndata[\"feat\"].shape[1]\n",
    "    )  # Assuming the first graph has the feature shape\n",
    "\n",
    "    # Determine the number of classes based on the unique labels\n",
    "    num_class = len(\n",
    "        torch.unique(torch.tensor(labels)).tolist()\n",
    "    )  # Use unique labels from the dataset\n",
    "\n",
    "    return train_data, valid_data, test_data, num_feats, num_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph, label in train_loader[0]:\n",
    "    print(graph, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
